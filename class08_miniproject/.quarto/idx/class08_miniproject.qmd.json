{"title":"Class 08: Breast Cancer Analysis Mini Project","markdown":{"yaml":{"title":"Class 08: Breast Cancer Analysis Mini Project","author":"Ashley Mazon (PID:A17478903)","format":"html","toc":true},"headingText":"Background","containsRefs":false,"markdown":"\n\n\nhe goal of this mini-project is for you to explore a complete analysis using the unsupervised learning techniques covered in class. You’ll extend what you’ve learned by combining PCA as a preprocessing step to clustering using data that consist of measurements of cell nuclei of human breast masses. This expands on our RNA-Seq analysis from last day.\n\nThe data itself comes from the Wisconsin Breast Cancer Diagnostic Data Set first reported by K. P. Benne and O. L. Mangasarian: “Robust Linear Programming Discrimination of Two Linearly Inseparable Sets”.\n\nValues in this data set describe characteristics of the cell nuclei present in digitized images of a fine needle aspiration (FNA) of a breast mass.\n\n## Data Import \n\nInput data file is saved into my Project directory as a CSV\n\n```{r}\nwisc.df <- read.csv(\"WisconsinCancer.csv\", row.names = 1)\nhead(wisc.df)\n\n```\n\n\nThe first column `diagnosis` is the expert opinion on the sample (i.e. patient FNA)\n```{r}\nwisc.df$diagnosis\n```\n\n\n-1 is used to remove the diagnosis column, which is not needed right now, but needed later as a vector\n\n```{r}\nwisc.data <- wisc.df[,-1]\ndiagnosis <- wisc.df[,1]\n```\n\nLastly, explore and get familiar \n\n>Q1. Q1. How many observations are in this dataset?\n\nThere are `r nrow(wisc.data)` observations/patients in the dataset.\n\n\n>Q2. How many of the observations have a malignant diagnosis?\n\nThere are 212 observations that have a malignant diagnosis.\n\n```{r}\ntable(wisc.df$diagnosis)\n```\n\n>Q3. How many variables/features in the data are suffixed with _mean?\n\n```{r}\ncolnames(wisc.data)\nlength(grep(\"_mean\", colnames(wisc.data)))\n```\n## Principal Coordinate Analysis \n\nThe `prcomp()` function to do PCA has a `scale=FALSE`default. In general we nearly always want to set this to TRUE so our analysis is not dominated by columns/variables in our data set that have high standard deviation and mean when compared to others just because the units of measurement are on different scales \n\n```{r}\nwisc.pr <- prcomp( wisc.data,scale=TRUE)\nsummary(wisc.pr)\n```\n\nThe main PC result figure is called a \"score plot\" or a \"PC polt\" or \"ordination plot\"...\n\n```{r}\nlibrary(ggplot2)\n\nggplot(wisc.pr$x)+\n  aes(PC1, PC2, col=diagnosis) +\n  geom_point()\n```\n\n\n\n> Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?\n\n44.27% of the original variance is captured by PC1\n\n```{r}\nsummary(wisc.pr)\n```\n\n\n> Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?\n\n3 principal components are required to describe at least 70% of the data \n\n> Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?\n\nAbout 8 principal components are requied to describe at least 90% of the original variance in the data \n\n\n\n\n##PCA Scree-plot \n\nA plot of how much variance each PC captures. We can get this from `wisc.pr$sdev` or from the output of `summary(wisc.pr)`\n\n```{r}\nvar.tbl <- summary(wisc.pr)\nhead(var.tbl$importance)\n\n```\n\n```{r}\npr.var <- wisc.pr$sdev^2\nhead(pr.var)\n```\n\nVariance explained by each principal component: pve\n```{r}\npve <- pr.var / sum(pr.var)\n\n```\n\n```{r}\nplot(pve, xlab = \"Principal Component\", \n     ylab = \"Proportion of Variance Explained\", \n     ylim = c(0, 1), type = \"o\")\n```\n\nAn alternative scree plot can be made \n\n```{r}\nscreeplot <- barplot(pve, ylab = \"Precent of Variance Explained\",\n     names.arg=paste0(\"PC\",1:length(pve)), las=2, axes = FALSE)\naxis(2, at=pve, labels=round(pve,2)*100 )\n```\n\n> Q9. For the first principal component, what is the component of the loading vector (i.e. `wisc.pr$rotation[,1]`) for the feature `concave.points_mean`?\n\n```{r}\nwisc.pr$rotation[\"concave.points_mean\", 1]\n\n```\n\n> Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?\n\n5 principal components are required to explain 80% of the variance of the data \n\n\n\n\n## Hierarchical clustering \n\nJust clusting the original data is not very informative or helpful \n\n```{r}\ndata.scaled <- scale(wisc.data)\ndata.dist <- dist(data.scaled)\nwisc.hclust <- hclust (data.dist)\n```\n\n```{r}\nplot (wisc.hclust)\n```\n```{r}\nwisc.hclust.clusters <- cutree(wisc.hclust, k=4)\ntable(cutree(wisc.hclust, k=4))\n```\n```{r}\ntable(wisc.hclust.clusters,diagnosis)\n```\n\n## Combining methods (PCA and Clustering)\n\nClustering the original data was not very productive. The PCA results looked promising. Here we combined these methods by clustering from our PCA results. In other words \"clustering in PC space\"\n\n```{r}\ndist.pc <- dist(wisc.pr$x[,1:3])\nwisc.pr.hclust <- hclust(dist.pc, method = \"ward.D2\")\n```\n\nView the tree... \n```{r}\nplot(wisc.pr.hclust)\nabline(h=70, col=\"red\")\n```\nTo get out clustering membership vector (i.e. out main clustering result) we \"cut\" the tree at a desired height or to yield a desired number of \"k\" \n\n```{r}\ngrps <- cutree(wisc.pr.hclust, h=70)\ntable(grps)\n```\nHow does this clustering grps compare to the expert diagnosis \n```{r}\ntable(grps, diagnosis)\n```\nSensitivity: TP/(TP+FN)\nSpecificity: TN/(TN+FN)\n\n## 7. Prediction \n\nWe can use out PCA model for prediction with new input patient samples. \n\n```{r}\n#url <- \"new_samples.csv\"\nurl <- \"https://tinyurl.com/new-samples-CSV\"\nnew <- read.csv(url)\nnpc <- predict(wisc.pr, newdata=new)\nnpc\n```\n\n","srcMarkdownNoYaml":"\n\n## Background \n\nhe goal of this mini-project is for you to explore a complete analysis using the unsupervised learning techniques covered in class. You’ll extend what you’ve learned by combining PCA as a preprocessing step to clustering using data that consist of measurements of cell nuclei of human breast masses. This expands on our RNA-Seq analysis from last day.\n\nThe data itself comes from the Wisconsin Breast Cancer Diagnostic Data Set first reported by K. P. Benne and O. L. Mangasarian: “Robust Linear Programming Discrimination of Two Linearly Inseparable Sets”.\n\nValues in this data set describe characteristics of the cell nuclei present in digitized images of a fine needle aspiration (FNA) of a breast mass.\n\n## Data Import \n\nInput data file is saved into my Project directory as a CSV\n\n```{r}\nwisc.df <- read.csv(\"WisconsinCancer.csv\", row.names = 1)\nhead(wisc.df)\n\n```\n\n\nThe first column `diagnosis` is the expert opinion on the sample (i.e. patient FNA)\n```{r}\nwisc.df$diagnosis\n```\n\n\n-1 is used to remove the diagnosis column, which is not needed right now, but needed later as a vector\n\n```{r}\nwisc.data <- wisc.df[,-1]\ndiagnosis <- wisc.df[,1]\n```\n\nLastly, explore and get familiar \n\n>Q1. Q1. How many observations are in this dataset?\n\nThere are `r nrow(wisc.data)` observations/patients in the dataset.\n\n\n>Q2. How many of the observations have a malignant diagnosis?\n\nThere are 212 observations that have a malignant diagnosis.\n\n```{r}\ntable(wisc.df$diagnosis)\n```\n\n>Q3. How many variables/features in the data are suffixed with _mean?\n\n```{r}\ncolnames(wisc.data)\nlength(grep(\"_mean\", colnames(wisc.data)))\n```\n## Principal Coordinate Analysis \n\nThe `prcomp()` function to do PCA has a `scale=FALSE`default. In general we nearly always want to set this to TRUE so our analysis is not dominated by columns/variables in our data set that have high standard deviation and mean when compared to others just because the units of measurement are on different scales \n\n```{r}\nwisc.pr <- prcomp( wisc.data,scale=TRUE)\nsummary(wisc.pr)\n```\n\nThe main PC result figure is called a \"score plot\" or a \"PC polt\" or \"ordination plot\"...\n\n```{r}\nlibrary(ggplot2)\n\nggplot(wisc.pr$x)+\n  aes(PC1, PC2, col=diagnosis) +\n  geom_point()\n```\n\n\n\n> Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?\n\n44.27% of the original variance is captured by PC1\n\n```{r}\nsummary(wisc.pr)\n```\n\n\n> Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?\n\n3 principal components are required to describe at least 70% of the data \n\n> Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?\n\nAbout 8 principal components are requied to describe at least 90% of the original variance in the data \n\n\n\n\n##PCA Scree-plot \n\nA plot of how much variance each PC captures. We can get this from `wisc.pr$sdev` or from the output of `summary(wisc.pr)`\n\n```{r}\nvar.tbl <- summary(wisc.pr)\nhead(var.tbl$importance)\n\n```\n\n```{r}\npr.var <- wisc.pr$sdev^2\nhead(pr.var)\n```\n\nVariance explained by each principal component: pve\n```{r}\npve <- pr.var / sum(pr.var)\n\n```\n\n```{r}\nplot(pve, xlab = \"Principal Component\", \n     ylab = \"Proportion of Variance Explained\", \n     ylim = c(0, 1), type = \"o\")\n```\n\nAn alternative scree plot can be made \n\n```{r}\nscreeplot <- barplot(pve, ylab = \"Precent of Variance Explained\",\n     names.arg=paste0(\"PC\",1:length(pve)), las=2, axes = FALSE)\naxis(2, at=pve, labels=round(pve,2)*100 )\n```\n\n> Q9. For the first principal component, what is the component of the loading vector (i.e. `wisc.pr$rotation[,1]`) for the feature `concave.points_mean`?\n\n```{r}\nwisc.pr$rotation[\"concave.points_mean\", 1]\n\n```\n\n> Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?\n\n5 principal components are required to explain 80% of the variance of the data \n\n\n\n\n## Hierarchical clustering \n\nJust clusting the original data is not very informative or helpful \n\n```{r}\ndata.scaled <- scale(wisc.data)\ndata.dist <- dist(data.scaled)\nwisc.hclust <- hclust (data.dist)\n```\n\n```{r}\nplot (wisc.hclust)\n```\n```{r}\nwisc.hclust.clusters <- cutree(wisc.hclust, k=4)\ntable(cutree(wisc.hclust, k=4))\n```\n```{r}\ntable(wisc.hclust.clusters,diagnosis)\n```\n\n## Combining methods (PCA and Clustering)\n\nClustering the original data was not very productive. The PCA results looked promising. Here we combined these methods by clustering from our PCA results. In other words \"clustering in PC space\"\n\n```{r}\ndist.pc <- dist(wisc.pr$x[,1:3])\nwisc.pr.hclust <- hclust(dist.pc, method = \"ward.D2\")\n```\n\nView the tree... \n```{r}\nplot(wisc.pr.hclust)\nabline(h=70, col=\"red\")\n```\nTo get out clustering membership vector (i.e. out main clustering result) we \"cut\" the tree at a desired height or to yield a desired number of \"k\" \n\n```{r}\ngrps <- cutree(wisc.pr.hclust, h=70)\ntable(grps)\n```\nHow does this clustering grps compare to the expert diagnosis \n```{r}\ntable(grps, diagnosis)\n```\nSensitivity: TP/(TP+FN)\nSpecificity: TN/(TN+FN)\n\n## 7. Prediction \n\nWe can use out PCA model for prediction with new input patient samples. \n\n```{r}\n#url <- \"new_samples.csv\"\nurl <- \"https://tinyurl.com/new-samples-CSV\"\nnew <- read.csv(url)\nnpc <- predict(wisc.pr, newdata=new)\nnpc\n```\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"class08_miniproject.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.32","title":"Class 08: Breast Cancer Analysis Mini Project","author":"Ashley Mazon (PID:A17478903)"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":[]}