---
title: "Class 7: Machine Learning 1"
author: "Ashley Mazon (PID: A17478903)"
format: pdf
---

Today we will explore some funamental machine learning methods including clusterings and dimensionality functions. 

## K-means clustering 

To see how this works let's first makeup some data to cluster where we know what the answer should be. We can use the `rnorm()` function to help here: 

```{r}

hist(rnorm(500, mean=5))
```


```{r}
x <- c(rnorm(30, mean=-3),rnorm(30, mean=3))
y <- rev(x)
```
```{r}
x <- cbind(x,y)
plot(x) 
```

The function for K-means clustering in "base" R si `kmeans()`

```{r}
k <- kmeans (x, centers=2)
k
```

To get at the results of the returned list object we can use the dollar `$` syntax

> Q. How many points are in each cluster?

```{r}
k$size
```

> Q. What 'component' of your result object details 
    - cluster assignment/membership?
    - cluster center? 
    
```{r}
k$cluster
```
```{r}
k$centers
```
  

>Q. Make a clustering results figure of the data colored by cluster membership 

```{r}
plot(x, col = c("maroon", "blue"))
```
```{r}
plot (x, col=2)
```
```{r}
plot(x, col=k$cluster, pch=16)
points(k$centers, col="orange", pch=15, cex=2)
```

K-means clustering is very populat as it is very fast and relatively straight forward: it takes numveric data as input and returns the cluster membership vector etc. 

The "issue" is we tell `kmeans()` how many clusters we want!

> Q. Run kmeans again and cluster into 4 groups.clusters and plot the results like we did above?

```{r}
k4 <- kmeans(x, centers = 4)

plot(x, col=k4$cluster)
points(k4$center, pch=15)
```

Scree plot to pick k `centers` value 


brute force
```{r}
k1 <- kmeans(x, center=1)
k2 <- kmeans(x, center=2)
k3 <- kmeans(x, center=3)
k4 <- kmeans(x, center=4)
k5 <- kmeans(x, center=5)

```


```{r}
z <- c(k1$tot.withinss, 
       k2$tot.withinss,
       k3$tot.withinss,
       k4$tot.withinss)

plot(z, typ="b")
```

```{r}
n <- NULL
for (i in 1:5) {
  n <- c(n, kmeans(x, centers=i)$tot.withinss)
}

plot (n,typ="b")
```

## Hierarchical Clustering 

The mean "base" R function for Hierarchical clustering called ` hclust()`. Here we can't just input our data, we need to first calculate a distance matrix (e.g. `dist()` for our data and use this as input to `hclust()`

```{r}
d <- dist(x)
hc <- hclust(d)
hc
```
There is a plot method for hclust reuslts, lets try it

```{r}
plot(hc)
abline(h=8, col="red")
cutree(hc, h=8)
```

To get our cluster "membership" vector (i.e. our main clustering result) we can "cut" the tree at a given height or at a height that yields a given "k" groups. 

```{r}
cutree(hc, h=8)
```

```{r}
grps <- cutree(hc, k=2)
```

> Q. Plot the data with our hclust result coloring


```{r}
plot (x, col=grps)
```


# Principal Component Analysis (PCA) 

## PCA of UK food data 

Import food data from a online CSV files. 

```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url)
head(x)
```

```{r}
rownames(x) <- x[,1]
x <- x[,-1]
x
```

```{r}
x <- read.csv(url, row.names=1)
x
```

Some base figures 
```{r}
barplot(as.matrix(x), beside=T, col=rainbow(nrow(x)))
```

```{r}
barplot(as.matrix(x), beside=F, col=rainbow(nrow(x)))

```


```{r}
pairs(x, col=rainbow(nrow(x)), pch=16)
```

> Main Point: It can be difficult to spot major trends and patterns even in relatively small multivariate datasets (here we only have 17 dimensions, typically we have 1000s). 

### PCA to the rescue 

The main function in "base" R for our PCA is called `prcomp()`

I will take the transpose of our data so the "foods" are in the columns
```{r}
pca <- prcomp(t(x))
summary(pca)
```
This tells me where each countries are on different PC axis
```{r}
pca$x
```
```{r}
cols <- c("orange", "red", "blue", "darkgreen") 
plot(pca$x[,1], pca$x[,2], col=cols, pch=16)
```

```{r}
library(ggplot2)

```


```{r}
ggplot(pca$x) +
  aes(PC1, PC2)+
  geom_point(col=cols)
```
```{r}
ggplot(pca$rotation) +
  aes(PC1, rownames(pca$rotation))+
  geom_col()
```
positive or negative contributions to the variance (ex. fresh potatoes and soft drinks are in the positive directions = ireland have more of these compared to other countries), positive and negative direction is the level of distinction. 


PCA looks super useful and we will come back to describe this further next day  :3











